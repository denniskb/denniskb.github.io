#- layout: top-middle
#  name: Super awesome project
#  link: github.com/sproogen
#  github: sproogen/resume-theme
#  quote: >
#    This is probably one of the greatest apps ever created, if you don't agree you're probably wrong.
#  description: | # this will include new lines to allow paragraphs
#    I started this project as a way if learning <mark>React</mark> and it has since grown into a fully fledged app. I have learned many skills through this and been I'm very proud of having this in my portfolio. If you don't have a project as awesome as this I would advise you make one.
- layout: top-middle
  name: <a name="hpec2021" href="#"></a>Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared Atomics
  quote: <a href="https://arxiv.org/abs/2107.04092v2">arxiv:2107.04092v2</a>
  description: | # this will include new lines to allow paragraphs
    <img style="display:block; margin:0 auto; width:800px;" src="images/hpec21.png"/>

    Two optimizations to speed up spike transmission and spike timing-based plasticity in clock-based SNN simulators. Both combined yield a > 2x speedup over our closest competitor, re-establishing ourselves as the fastest simulator.

    **Resources**:
    - <img class="icon" src="images/pdf.png"/> [Paper](https://drive.google.com/file/d/16gNt_U3hbAw0OV56bHO3eVs238x7g2IB/view?usp=sharing)
    - <img class="icon" src="images/git.png"/> [Source code](https://github.com/denniskb/spice/tree/gather)

- layout: top-middle
  name: <a name="ijcnn2021" href="#"></a>Multi-GPU SNN Simulation with Static Load Balancing
  quote: <a href="https://doi.org/10.1109/IJCNN52387.2021.9533921">10.1109/IJCNN52387.2021.9533921</a>
  description: | # this will include new lines to allow paragraphs
    <iframe width="560" height="315" src="https://www.youtube.com/embed/bXwnmT0zqUM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    
    We present the first SNN simulator to scale to 8 GPUs, allowing you to simulate larger models and in less time than ever before. Features include:
    - State of the art performance (incl. lightning fast setup)
    - Ability to define custom models in native C++
    - Modern, user-friendly API
    - No 3rd-party dependencies (except CUDA)    
    
    **Resources**:
    - <img class="icon" src="images/pdf.png"/> [Paper](https://drive.google.com/file/d/19gUwSEJ-4hYYDnUjttG37V1J2ZmS81Tt/view?usp=sharing)
    - <img class="icon" src="images/git.png"/> [Source code](https://github.com/denniskb/spice)
    
- layout: top-middle
  name: <a name="ijcnn2020" href="#"></a>Faster and Simpler SNN Simulation with Work Queues
  quote: <a href="https://doi.org/10.1109/IJCNN48605.2020.9206752">10.1109/IJCNN48605.2020.9206752</a>
  description: | # this will include new lines to allow paragraphs
    <iframe width="560" height="315" src="https://www.youtube.com/embed/A4GEVUXi5js" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  
    "Spice" is a state of the art spiking neural network simulator written in C++ and CUDA. It
    - is up to 3x faster than the competition,
    - allows you to specify your own models through a modern and intuitive API (you simply inherit from a model base class and override callbacks),
    - builds out of the box without any 3rd-party dependencies (apart from CUDA), and
    - does not involve any proprietary compilation steps or domain-specific languages.
    
    **Resources**:
    - <img class="icon" src="images/pdf.png"/> [Paper](https://drive.google.com/file/d/1VQy950BeyIn06DSEVHrjbcMSbYn-VQVv/view?usp=sharing)
    - <img class="icon" src="images/git.png"/> [Source code](https://github.com/denniskb/spice)
    
- layout: top-middle
  name: <a name="petra2018" href="#"></a>A Comparative Study of Matrix Completion and Recovery Techniques for Human Pose Estimation
  quote: <a href="https://doi.org/10.3390/technologies6040097">10.3390/technologies6040097</a>
  description: | # this will include new lines to allow paragraphs
    <iframe width="560" height="315" src="https://www.youtube.com/embed/kqW4qFYzjug" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    We estimate human poses by treating them as missing/incomplete rows in a "pose database" matrix and calculating missing entries via matrix completion.
    
    <img class="icon" src="images/pdf.png"/> [Paper](https://drive.google.com/file/d/1KjbFcSWh6folu6oz8NeEeMGG2jGLinGL/view?usp=sharing)
    
- layout: top-middle
  name: <a name="hdfusion" href="#"></a>Scalable Real-time Volumetric Surface Reconstruction
  quote: <a href="https://doi.org/10.1145/2461912.2461940">10.1145/2461912.2461940</a>
  description: | # this will include new lines to allow paragraphs
    <iframe width="560" height="315" src="https://www.youtube.com/embed/RR2fhy35oaY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  
    [KinectFusion](https://www.microsoft.com/en-us/research/project/kinectfusion-project-page/) is a well-known 3D scanner powered by Microsoftâ€™s Kinect camera. It has recently found its way into the official [Kinect for Windows SDK](https://www.microsoft.com/en-us/download/details.aspx?id=44561). While KinectFusion produces very high-quality scans in real-time, it is limited to relatively small spaces.

    In this paper we extend KinectFusion with a sparse data structure and streaming, allowing us to scan areas of virtually infinite size while maintaining the quality and performance of the original algorithm.
    
    **Resources**:
    - <img class="icon" src="images/pdf.png"/> [Paper](https://drive.google.com/file/d/0B8mr2Y3MS0dgMzE2VGpzWHJPQ28/view?usp=sharing)
    
- layout: top-middle
  name: <a name="asvo" href="#"></a>Animated Sparse Voxel Octrees
  quote: >
    Unpublished BSc thesis
  description: | # this will include new lines to allow paragraphs
    <iframe width="560" height="315" src="https://www.youtube.com/embed/tkn6ubbp1SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    
    Voxels date back [20 years](http://advsys.net/ken/voxlap.htm). They have many advantages over polygon meshes. However, they always suffered form the lack of a hardware-accelerated rendering pipeline and the infeasiblity of animating them. I tackled this age-old computer graphics problem in my BSc thesis. The (GPU-accelerated) animation technique I developed enables:
    
    - Skeletal animation of voxels models
    - Rendering of mixed polygon- and voxel-based content.
    
    **Resources**:
    - <img class="icon" src="images/pdf.png"/> [BSc thesis](https://drive.google.com/file/d/0B8mr2Y3MS0dgS0ktekNmUzBUeGc/view?usp=sharing)
    - <img class="icon" src="images/yt.png"/> [In-depth video tutorial series](https://www.youtube.com/watch?v=Tl6PE_n6zTk&list=PLfuJEfUHg4HGC-pS85iam40FmG9vyLYcR)
    - <img class="icon" src="images/git.png"/> [Source code](https://github.com/denniskb/asvo)
